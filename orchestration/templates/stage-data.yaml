apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: stage-data
spec:
  entrypoint: main
  onExit: {{ if .Values.notification.onlyOnFailure }}send-slack-notification-if-failed{{ else }}send-slack-notification{{ end }}
  serviceAccountName: {{ .Values.serviceAccount.k8sName }}
  templates:
    - name: main
      inputs:
        parameters:
          - name: source-bucket-name
          {{- $inputBucket := "{{inputs.parameters.source-bucket-name}}" }}
          - name: source-bucket-prefix
          {{- $inputPrefix := "{{inputs.parameters.source-bucket-prefix}}" }}
          - name: staging-bucket-prefix
          {{- $stagingPrefix := "{{inputs.parameters.staging-bucket-prefix}}" }}
      # Limit the number of active processing "arms" at a time.
      # There may be multiple pods running within each arm.
      parallelism: {{ .Values.parallelism }}
      dag:
        tasks:
          # Clear the staging directory to avoid corrupt state.
          - name: clear-staging-dir
            template: delete-gcs-directory
            arguments:
              parameters:
                - name: gcs-prefix
                  value: {{ $stagingPrefix | quote }}

          # Pre-process the metadata found in a source bucket
          - name: pre-process-metadata
            dependencies: [clear-staging-dir]
            template: run-dataflow
            arguments:
              parameters:
                - name: source-bucket-name
                  value: {{ $inputBucket | quote }}
                - name: source-bucket-prefix
                  value: {{ $inputPrefix | quote }}
                - name: staging-bucket-prefix
                  value: {{ $stagingPrefix | quote }}

          {{- $datasetName := printf "%s_%s" .Values.bigquery.stagingData.datasetPrefix $stagingPrefix }}

    ##
    ## Delete all the files under a prefix in GCS.
    ##
    - name: delete-gcs-directory
      inputs:
        parameters:
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
      script:
        image: google/cloud-sdk:slim
        {{- $fullPath := printf "gs://%s/%s/*" .Values.gcs.stagingBucketName $gcsPrefix }}
        command: [bash]
        source: |
          # rm will fail if there's already nothing at the target path.
          gsutil -m rm -r {{ $fullPath }} || true

    ##
    ## Run a Dataflow job to pre-process JSON metadata from the input area,
    ## moving it into our GCP space in the process.
    ##
    - name: run-dataflow
      inputs:
        parameters:
          - name: source-bucket-name
          {{- $sourceBucket := "{{inputs.parameters.source-bucket-name}}" }}
          - name: source-bucket-prefix
          {{- $sourcePrefix := "{{inputs.parameters.source-bucket-prefix}}" }}
          - name: staging-bucket-prefix
          {{- $stagingPrefix := "{{inputs.parameters.staging-bucket-prefix}}" }}
      container:
        {{- $version := default "latest" .Chart.AppVersion }}
        image: us.gcr.io/broad-dsp-gcr-public/hca-transformation-pipeline:{{ $version }}
        command: []
        args:
          - --runner=dataflow
          - --inputPrefix=gs://{{ $sourceBucket }}{{ $sourcePrefix }}
          - --outputPrefix=gs://{{ .Values.gcs.stagingBucketName }}/{{ $stagingPrefix }}
          {{- with .Values.dataflow }}
          - --project={{ .project }}
          - --region={{ .region }}
          - --tempLocation=gs://{{ .tmpBucketName }}/dataflow
          - --subnetwork=regions/{{ .region }}/subnetworks/{{ .subnetName }}
          - --serviceAccount={{ .workerAccount }}
          - --workerMachineType={{ .workerMachineType }}
          {{- with .autoscaling }}
          - --autoscalingAlgorithm=THROUGHPUT_BASED
          - --numWorkers={{ .minWorkers }}
          - --maxNumWorkers={{ .maxWorkers }}
          {{- end }}
          {{- if .useFlexRS }}
          - --flexRSGoal=COST_OPTIMIZED
          {{- else }}
          - --experiments=shuffle_mode=service
          {{- end }}
          {{- end }}
    ##
    ## Send a Slack notifcation if the workflow has failed.
    ##
    - name: send-slack-notification-if-failed
      steps:
        - - name: send-notification
            template: send-slack-notification
            when: {{ "{{workflow.status}} != Succeeded" | quote }}
    ## send a slack notification
    ## TBD: can this be a template ref
    - name: send-slack-notification
      container:
        image: curlimages/curl:7.70.0
        env:
          - name: WORKFLOW_ID
            value: {{ "{{workflow.name}}" | quote }}
          - name: WORKFLOW_STATE
            value: {{ "{{workflow.status}}" | quote }}
          - name: OAUTH_TOKEN
            valueFrom:
              secretKeyRef:
                name: {{ .Values.notification.oauthToken.secretName }}
                key: {{ .Values.notification.oauthToken.secretKey }}
        command: [ curl ]
        args:
          - -XPOST
          - -H
          - 'Content-type: application/json'
          - -H
          - 'Authorization: Bearer ${OAUTH_TOKEN}'
          - -d
          - '{"text": "Workflow ${WORKFLOW_ID} entered state: ${WORKFLOW_STATE", "channel": "monster-ci"}'
          - "https://slack.com/api/chat.postMessage"
